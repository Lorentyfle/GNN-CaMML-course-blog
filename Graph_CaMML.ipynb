{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph neural network - CaMML course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do a GNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to this approach we can transform the theory into an useable algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorentyfle/test/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Here we will take some libraries to construct the neural-networks using torch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Here are some diverse modules and functions necessary.\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Local library for extracting data.\n",
    "from utils import MaterialsDataset, collate_fn, plot_sample, scatter_sum, scatter_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 8790\n",
      "Number of validation examples: 1099\n",
      "Number of testing examples: 1098\n"
     ]
    }
   ],
   "source": [
    "# To ensure a reproducible results, we put the same random seed.\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# We will also take the matbench data base log_gvrh data set with 10,987 VRH-average shear moduli calculated using DFT. As a starting data base for training and testing the GNN we will create in this section.\n",
    "\n",
    "dataset = MaterialsDataset(\n",
    "    \"./inputs/bulk-modulus-dataset.json\",\n",
    "    cutoff=4,  # cutoff radius for finding neighbours\n",
    "    num_gaussians=40,  # number of gaussians in edge embedding\n",
    ")\n",
    "# Sample of the data to visualise it.\n",
    "sample = dataset[10]\n",
    "# You can visualise one of structure that was sampled.\n",
    "# Here, we can see the crystal structure in the left and the graph this crystal structure will provide on the right:\n",
    "plot_sample(sample)\n",
    "\n",
    "# From here we split the data set into a training and a validation data set.\n",
    "train_set, valid_set, test_set = random_split(dataset, [0.8, 0.1, 0.1])\n",
    "print(f'Number of training examples: {len(train_set)}')\n",
    "print(f'Number of validation examples: {len(valid_set)}')\n",
    "print(f'Number of testing examples: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data is splitted into batches to make the datas more manageable to compute.\n",
    "# collate_fn allows to automatically handle grouping multiple graphs into a batch.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training part of the data.\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True,\n",
    ")\n",
    "# Validation part of the data.\n",
    "valid_loader = DataLoader(\n",
    "    valid_set, batch_size=BATCH_SIZE, collate_fn=collate_fn,\n",
    ")\n",
    "# Testing part of the data.\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=BATCH_SIZE, collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I first need to do convolution\n",
    "# EXPLAIN WHY\n",
    "# EXPLAIN ALL THE STEPS\n",
    "class GraphConvolution(nn.Module):\n",
    "    \n",
    "    def __init__(self, node_feat_dim, edge_feat_dim):\n",
    "        \"\"\"\n",
    "        Convolutional layer for graphs.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node_feat_dim : int\n",
    "          Number of node features.\n",
    "        edge_feat_dim : int\n",
    "          Number of edge features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # linear layer used for the gated MLP\n",
    "        self.lin1 = nn.Linear(\n",
    "            2 * node_feat_dim + edge_feat_dim,\n",
    "            2 * node_feat_dim,\n",
    "        )\n",
    "\n",
    "        # normalisation layers\n",
    "        self.bn1 = nn.BatchNorm1d(2 * node_feat_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(node_feat_dim)\n",
    "\n",
    "    def forward(self, node_feat, edge_feat, edge_src, edge_dst):\n",
    "        \"\"\"Perform the convolution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node_feat : Tensor\n",
    "            The node features.\n",
    "        edge_feat : Tensor\n",
    "            The edge features\n",
    "        edge_src : Tensor\n",
    "            The indices of the central nodes for the edges.\n",
    "        edge_dst : Tensor\n",
    "            The indices of the desintation nodes for the edges.\n",
    "        \"\"\"\n",
    "        # concatenate node and edge features\n",
    "        m = torch.cat([node_feat[edge_src], node_feat[edge_dst], edge_feat], dim=1)\n",
    "\n",
    "        # gated MLP\n",
    "        z = self.lin1(m)\n",
    "        z = self.bn1(z)\n",
    "        z1, z2 = z.chunk(2, dim=1)\n",
    "        z1 = nn.Sigmoid()(z1)\n",
    "        z2 = nn.Softplus()(z2)\n",
    "        z = z1 * z2\n",
    "\n",
    "        # pool features\n",
    "        z = scatter_sum(z, edge_src, dim=0, dim_size=node_feat.shape[0])\n",
    "        \n",
    "        # pass through normalisation layer\n",
    "        return nn.Softplus()(self.bn2(z) + node_feat)\n",
    "\n",
    "\n",
    "# Then I do CGCNN \n",
    "# WHY\n",
    "# EXPLAIN ALL THE LINES.\n",
    "class CGCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_feat_dim,\n",
    "        edge_feat_dim,\n",
    "        node_hidden_dim=64,\n",
    "        num_graph_conv_layers=3,\n",
    "        fc_feat_dim=128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Crystal Graph Convolutional Neural Network \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node_feat_dim : int\n",
    "          Number of initial node features from one-hot encoding.\n",
    "        edge_feat_dim : int\n",
    "          Number of bond features.\n",
    "        node_hidden_dim : int\n",
    "          The number of features in the node embedding.\n",
    "        num_graph_conv_layers: int\n",
    "          Number of convolutional layers.\n",
    "        fc_feat_dim: int\n",
    "          Number of hidden features after pooling.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # dense layer to transform one-hot encoded node features to embedding\n",
    "        self.embedding = nn.Linear(node_feat_dim, node_hidden_dim)\n",
    "\n",
    "        # set up the convolutions\n",
    "        convs = []\n",
    "        for _ in range(num_graph_conv_layers):\n",
    "            convs.append(GraphConvolution(node_feat_dim=node_hidden_dim, edge_feat_dim=edge_feat_dim))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "\n",
    "        # dense layer to turn final node embeddings to the crystal features\n",
    "        self.conv_to_fc = nn.Sequential(\n",
    "           nn.Linear(node_hidden_dim, fc_feat_dim), nn.Softplus()\n",
    "        )\n",
    "\n",
    "        # dense layer to get the final target value\n",
    "        self.fc_out = nn.Linear(fc_feat_dim, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Predict the target property given a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Batch\n",
    "            The data to pass through the network.\n",
    "        \"\"\"\n",
    "        # get initial node embedding\n",
    "        node_feat = self.embedding(batch.node_feat)\n",
    "\n",
    "        # apply convolutions\n",
    "        for conv_func in self.convs:\n",
    "            node_feat = conv_func(node_feat, batch.edge_feat, batch.edge_src, batch.edge_dst)\n",
    "\n",
    "        # pool node vectors\n",
    "        crys_feat = scatter_mean(node_feat, batch.batch, dim=0, dim_size=batch.batch.max() + 1)\n",
    "\n",
    "        # pass pooled vector through FC layer with activation\n",
    "        crys_feat = self.conv_to_fc(crys_feat)\n",
    "\n",
    "        # pass crystal features through final fully-connected layer\n",
    "        return self.fc_out(crys_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Use of GNN to run an MD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
