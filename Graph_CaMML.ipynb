{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph neural network - CaMML course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do a GNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to this approach we can transform the theory into an useable algorithm.\n",
    "\n",
    "To do so, we will take the time to build piece by piece our own GNN in this section. \n",
    "\n",
    "First of all, we need to have access to a sufficient amount of data to train our GNN, for this, the __[Materials Data Facility](https://materialsdatafacility.org/)__ database will be used (because we can connect anonymously). Even if we could train our GNN upon any property, we will only focus on the prediction of the formation energy of the solid using its structure and its composition.\n",
    "\n",
    "The extraction and handeling of the data will be similar to what is shown in the [matminer tutorial](https://github.com/hackingmaterials/matminer_examples/blob/main/matminer_examples/machine_learning-nb/formation_e.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorentyfle/test/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Here we will take some libraries to construct the neural-networks using torch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Here are some diverse modules and functions necessary.\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matminer\n",
    "from matminer.data_retrieval.retrieve_MDF import MDFDataRetrieval\n",
    "from matminer.featurizers.conversions import StrToComposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure a reproducible results, we put the same random seed.\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting login with Globus Auth, press ^C to cancel.\n"
     ]
    }
   ],
   "source": [
    "mdf = MDFDataRetrieval(anonymous=True)\n",
    "# Here the amount of data loaded is small to avoid to wait one entire hour.\n",
    "data = mdf.get_data('mdf.source_name:oqmd AND (oqmd.configuration:static OR '\\\n",
    "    'oqmd.configuration:standard) AND dft.converged:True AND mdf.scroll_id:<10000', unwind_arrays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data base is ready, we will only need three columns to train our GNN upon:\n",
    " - The composition\n",
    " - The structure\n",
    " - The formation energy (the property we wish to predict)\n",
    "\n",
    "Such that we can take the following columns:\n",
    " - `material.composition`\n",
    " - `material.???`\n",
    " - `oqmd.delta_e.value`\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['oqmd.delta_e.value', 'material.composition']] # Needs to add the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property searched upon being the formation energy then, only the lowest-energy entry will be kept (of course compounds without `delta_e` measurements and outliers will be removed from the database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortcut for Input and Output columns.\n",
    "data = StrToComposition(target_col_id='composition_obj').featurize_dataframe(data, 'composition')\n",
    "\n",
    "print('=== Remove compounds without delta_e measurements ===')\n",
    "for k in ['delta_e']:\n",
    "    data[k] = pd.to_numeric(data[k])\n",
    "original_count = len(data)\n",
    "data = data[~ data['delta_e'].isnull()]\n",
    "print('Removed %d/%d entries'%(original_count - len(data), original_count))\n",
    "\n",
    "print('=== Get only the groundstate of each compositions ===')\n",
    "original_count = len(data)\n",
    "data['composition'] = data['composition_obj'].apply(lambda x: x.reduced_formula)\n",
    "data.sort_values('delta_e', ascending=True, inplace=True)\n",
    "data.drop_duplicates('composition', keep='first', inplace=True)\n",
    "print('Removed %d/%d entries'%(original_count - len(data), original_count))\n",
    "\n",
    "print('=== Remove outliers ===')\n",
    "original_count = len(data)\n",
    "data = data[np.logical_and(data['delta_e'] >= -20, data['delta_e'] <= 5)]\n",
    "print('Removed %d/%d entries'%(original_count - len(data), original_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Need to split the datas in function of composition in between train, validation and test.\n",
    "- Need to do batches of the datas.\n",
    "\n",
    "- run the entire GNN code to see if it is working as expected with the new inputs.\n",
    "\n",
    "- Create GNN \"step by step\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- DRAFT ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure a reproducible results, we put the same random seed.\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# We will also take the matbench data base log_gvrh data set with 10,987 VRH-average shear moduli calculated using DFT. As a starting data base for training and testing the GNN we will create in this section.\n",
    "\n",
    "dataset = MaterialsDataset(\n",
    "    \"./inputs/bulk-modulus-dataset.json\",\n",
    "    cutoff=4,  #Â cutoff radius for finding neighbours\n",
    "    num_gaussians=40,  # number of gaussians in edge embedding\n",
    ")\n",
    "# Sample of the data to visualise it.\n",
    "sample = dataset[10]\n",
    "# You can visualise one of structure that was sampled.\n",
    "# Here, we can see the crystal structure in the left and the graph this crystal structure will provide on the right:\n",
    "plot_sample(sample)\n",
    "\n",
    "# From here we split the data set into a training and a validation data set.\n",
    "train_set, valid_set, test_set = random_split(dataset, [0.8, 0.1, 0.1])\n",
    "print(f'Number of training examples: {len(train_set)}')\n",
    "print(f'Number of validation examples: {len(valid_set)}')\n",
    "print(f'Number of testing examples: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected data treatment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the data is splitted into batches to make the datas more manageable to compute.\n",
    "# collate_fn allows to automatically handle grouping multiple graphs into a batch.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training part of the data.\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True,\n",
    ")\n",
    "# Validation part of the data.\n",
    "valid_loader = DataLoader(\n",
    "    valid_set, batch_size=BATCH_SIZE, collate_fn=collate_fn,\n",
    ")\n",
    "# Testing part of the data.\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=BATCH_SIZE, collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I first need to do convolution\n",
    "# EXPLAIN WHY\n",
    "# EXPLAIN ALL THE STEPS\n",
    "class GraphConvolution(nn.Module):\n",
    "    \n",
    "    def __init__(self, node_feat_dim, edge_feat_dim):\n",
    "        \"\"\"\n",
    "        Convolutional layer for graphs.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node_feat_dim : int\n",
    "          Number of node features.\n",
    "        edge_feat_dim : int\n",
    "          Number of edge features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # linear layer used for the gated MLP\n",
    "        self.lin1 = nn.Linear(\n",
    "            2 * node_feat_dim + edge_feat_dim,\n",
    "            2 * node_feat_dim,\n",
    "        )\n",
    "\n",
    "        # normalisation layers\n",
    "        self.bn1 = nn.BatchNorm1d(2 * node_feat_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(node_feat_dim)\n",
    "\n",
    "    def forward(self, node_feat, edge_feat, edge_src, edge_dst):\n",
    "        \"\"\"Perform the convolution.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node_feat : Tensor\n",
    "            The node features.\n",
    "        edge_feat : Tensor\n",
    "            The edge features\n",
    "        edge_src : Tensor\n",
    "            The indices of the central nodes for the edges.\n",
    "        edge_dst : Tensor\n",
    "            The indices of the desintation nodes for the edges.\n",
    "        \"\"\"\n",
    "        # concatenate node and edge features\n",
    "        m = torch.cat([node_feat[edge_src], node_feat[edge_dst], edge_feat], dim=1)\n",
    "\n",
    "        # gated MLP\n",
    "        z = self.lin1(m)\n",
    "        z = self.bn1(z)\n",
    "        z1, z2 = z.chunk(2, dim=1)\n",
    "        z1 = nn.Sigmoid()(z1)\n",
    "        z2 = nn.Softplus()(z2)\n",
    "        z = z1 * z2\n",
    "\n",
    "        # pool features\n",
    "        z = scatter_sum(z, edge_src, dim=0, dim_size=node_feat.shape[0])\n",
    "        \n",
    "        # pass through normalisation layer\n",
    "        return nn.Softplus()(self.bn2(z) + node_feat)\n",
    "\n",
    "\n",
    "# Then I do CGCNN \n",
    "# WHY\n",
    "# EXPLAIN ALL THE LINES.\n",
    "class CGCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_feat_dim,\n",
    "        edge_feat_dim,\n",
    "        node_hidden_dim=64,\n",
    "        num_graph_conv_layers=3,\n",
    "        fc_feat_dim=128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Crystal Graph Convolutional Neural Network \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node_feat_dim : int\n",
    "          Number of initial node features from one-hot encoding.\n",
    "        edge_feat_dim : int\n",
    "          Number of bond features.\n",
    "        node_hidden_dim : int\n",
    "          The number of features in the node embedding.\n",
    "        num_graph_conv_layers: int\n",
    "          Number of convolutional layers.\n",
    "        fc_feat_dim: int\n",
    "          Number of hidden features after pooling.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # dense layer to transform one-hot encoded node features to embedding\n",
    "        self.embedding = nn.Linear(node_feat_dim, node_hidden_dim)\n",
    "\n",
    "        # set up the convolutions\n",
    "        convs = []\n",
    "        for _ in range(num_graph_conv_layers):\n",
    "            convs.append(GraphConvolution(node_feat_dim=node_hidden_dim, edge_feat_dim=edge_feat_dim))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "\n",
    "        # dense layer to turn final node embeddings to the crystal features\n",
    "        self.conv_to_fc = nn.Sequential(\n",
    "           nn.Linear(node_hidden_dim, fc_feat_dim), nn.Softplus()\n",
    "        )\n",
    "\n",
    "        # dense layer to get the final target value\n",
    "        self.fc_out = nn.Linear(fc_feat_dim, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Predict the target property given a batch of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : Batch\n",
    "            The data to pass through the network.\n",
    "        \"\"\"\n",
    "        # get initial node embedding\n",
    "        node_feat = self.embedding(batch.node_feat)\n",
    "\n",
    "        # apply convolutions\n",
    "        for conv_func in self.convs:\n",
    "            node_feat = conv_func(node_feat, batch.edge_feat, batch.edge_src, batch.edge_dst)\n",
    "\n",
    "        # pool node vectors\n",
    "        crys_feat = scatter_mean(node_feat, batch.batch, dim=0, dim_size=batch.batch.max() + 1)\n",
    "\n",
    "        # pass pooled vector through FC layer with activation\n",
    "        crys_feat = self.conv_to_fc(crys_feat)\n",
    "\n",
    "        #Â pass crystal features through final fully-connected layer\n",
    "        return self.fc_out(crys_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Use of GNN to run an MD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
